{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Correlation: calculating Bivariate Moran's I and Local Moran's I with census data retrieved from CENSUS API\n",
    "\n",
    "This notebook demonstrates how to calculate Bivariate Moran's I and Local Moran's I based on census data. To be specific, it employs census tract level Social Vulnerability Index (SVI) data, focusing on Chicago, Illinois. \n",
    "\n",
    "### Data: \n",
    "* Census Tracts: https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html <br>\n",
    "* Social Vulnerability Index (SVI): https://www.atsdr.cdc.gov/placeandhealth/svi/documentation/SVI_documentation_2020.html\n",
    "\n",
    "Social Vulnerability Index (SVI) is a measure of the social vulnerability of a community. It is calculated based on 16 variables, including poverty, lack of vehicle access, and crowded housing. The SVI is calculated at the census tract level, with a higher value indicating a higher level of social vulnerability. The SVI data used in this notebook is from the Centers for Disease Control and Prevention (CDC) and is based on the 2020 SVI dataset.\n",
    "\n",
    "![](https://www.atsdr.cdc.gov/placeandhealth/svi/documentation/SVI-Variables.png?_=02699)\n",
    "\n",
    "Source: https://www.atsdr.cdc.gov/placeandhealth/svi/documentation/SVI_documentation_2020.html\n",
    "\n",
    "\n",
    "### Steps:\n",
    "1. Retrieve census data\n",
    "2. Calculate non-spatial correlation\n",
    "3. Calculate spatial correlation (Bivariate Moran's I & Bivariate Local Moran's I)\n",
    "4. K-means clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages\n",
    "\n",
    "A Python package is a way of organizing related Python modules into a single directory hierarchy. It provides a mechanism for grouping Python code files, resources, and configuration settings in a structured manner, making it easier to manage and distribute code. They also facilitate code reuse and distribution by allowing developers to bundle related functionality together and share it with others.\n",
    "\n",
    "The following packages are used in this notebook:<br>\n",
    "`requests` is a Python package to send HTTP requests using Python. It allows you to send HTTP requests and get responses from the web. <br>\n",
    "source: https://requests.readthedocs.io/en/latest/ <br>\n",
    "\n",
    "`libpysal` is a Python package for spatial analysis. It provides foundational algorithms and data structures that support the rest of the library. <br>\n",
    "source: https://pysal.org/libpysal/ <br>\n",
    "\n",
    "`esda` is a Python package and implements methods for the analysis of both global (map-wide) and local (focal) spatial autocorrelation, for both continuous and binary data. In addition, the package increasingly offers cutting-edge statistics about boundary strength and measures of aggregation error in statistical analyses. <br>\n",
    "source: https://pysal.org/esda/index.html <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Packages\n",
    "import requests\n",
    "import libpysal\n",
    "import esda\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Packages that investigated in the previous project\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Etc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Census tracts of Chicago, IL\n",
    "tract_geom = gpd.read_file('./data/tracts_Cook_IL.geojson')\n",
    "tract_geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the boundary of the tracts\n",
    "tract_geom.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Retrieve Census Data\n",
    "\n",
    "The American Community Survey (ACS) is an ongoing survey that provides data every year -- giving communities the current information they need to plan investments and services. The ACS covers a broad range of topics about social, economic, demographic, and housing characteristics of the U.S. population.\n",
    "\n",
    "*HOWEVER*, manually downloading the data from the ACS website is tedious. The Census Bureau provides an API (Application Programming Interface) to access the data. The API is a way to access the data in a structured way. The API allows you to request data from the Census Bureau and receive it in a format that is easy to work with.\n",
    "\n",
    "https://www.census.gov/data/developers/data-sets/acs-5year.2020.html#list-tab-1806015614\n",
    "\n",
    "To use API, you need to request an API key from the Census Bureau. The API key is a unique identifier that is used to authenticate requests associated with your project for usage and billing purposes.\n",
    "\n",
    "https://api.census.gov/data/key_signup.html\n",
    "\n",
    "After you submit the request, you will receive an email with the API key. Check your email and copy the API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'S1701_C01_040E' # ALL INDIVIDUALS WITH INCOME BELOW 150% OF POVERTY LEVEL\n",
    "state = '17'\n",
    "county = '031'\n",
    "API_KEY = 'YOUR API KEY' # Paste your API key here \n",
    "\n",
    "api_address = f'https://api.census.gov/data/2020/acs/acs5/subject?get=NAME,{table_name}&for=tract:*&in=state:{state}&in=county:{county}&key={API_KEY}'\n",
    "api_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you see 200 as the output, it means the request was successful\n",
    "requests.get(api_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the response to a JSON object\n",
    "# The output will be a nested list. The first element of the list is the header and the rest are the data\n",
    "response = requests.get(api_address).json()\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the first list, which will become the header of the DataFrame\n",
    "response[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the rest of the lists, which will become the data of the DataFrame\n",
    "response[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the response of API request\n",
    "results = pd.DataFrame(response[1:], columns=response[0])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggretate State, County, and Tract codes to create GEOID\n",
    "results['GEOID'] = results['state'] + results['county'] + results['tract']\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the results with the tract geometries\n",
    "tract_pov = tract_geom.merge(results, on='GEOID')\n",
    "tract_pov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column name (S1701_C01_040E) to a more meaningful name (Poverty_count)\n",
    "tract_pov = tract_pov.rename(columns={'S1701_C01_040E': 'Poverty_count'})\n",
    "tract_pov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the poverty count, but the result will be problematic due to the data type\n",
    "tract_pov.plot('Poverty_count', figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the statistics of the column \n",
    "tract_pov['Poverty_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data type of the columns in the DataFrame\n",
    "tract_pov.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data type of the column to integer\n",
    "tract_pov['Poverty_count'] = tract_pov['Poverty_count'].astype(int)\n",
    "\n",
    "# Check the data type of the columns in the DataFrame\n",
    "tract_pov.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the poverty count, but still the result is misleading since the data is not normalized per population in each tract\n",
    "tract_pov.plot('Poverty_count', legend=True,  figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the poverty ratio by dividing the poverty count by the population\n",
    "tract_pov['Poverty_ratio'] = tract_pov['Poverty_count'] / tract_pov['Pop'] # Some tracts have no population, resulting NaN in the ratio\n",
    "tract_pov['Poverty_ratio'] = tract_pov['Poverty_ratio'].fillna(0) # Replace NaN with 0\n",
    "tract_pov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the statistics of the column \n",
    "tract_pov['Poverty_ratio'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the poverty ratio\n",
    "tract_pov.plot('Poverty_ratio', legend=True, figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### *Exercise*\n",
    "1. (3 points) Retrive Census data with the following parameters:\n",
    "* Table Name: 'S2701_C05_001E' # Percent of people without health insurance\n",
    "* State: '17' # Illinois\n",
    "* County: '031' # Cook County\n",
    "* API KEY: 'Your API Key' \n",
    "        \n",
    "\n",
    "```python\n",
    "table_name = '' # Table Name as a string\n",
    "state = '' # State ID as a string\n",
    "county = '' # County ID as a string\n",
    "API_KEY = '' # Your API Key as a string\n",
    "\n",
    "api_address_text = f'https://api.census.gov/data/2020/acs/acs5/subject?get={table_name}&for=tract:*&in=state:{state}&in=county:{county}&key={API_KEY}'\n",
    "response_list = requests.get(api_address_text).json()\n",
    "response_list\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "table_name = '' # Table Name as a string\n",
    "state = '' # State ID as a string\n",
    "county = '' # County ID as a string\n",
    "API_KEY = '' # Your API Key as a string\n",
    "\n",
    "api_address_text = f'https://api.census.gov/data/2020/acs/acs5/subject?get={table_name}&for=tract:*&in=state:{state}&in=county:{county}&key={API_KEY}'\n",
    "response_list = requests.get(api_address_text).json()\n",
    "response_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Test code for the previous function. \n",
    "This cell should NOT give any errors when it is run.\"\"\"\n",
    "\n",
    "assert table_name == 'S2701_C05_001E'\n",
    "assert state == '17'\n",
    "assert county == '031'\n",
    "# assert API_KEY != '5ad4c26135eaa6a049525767607eecd39e19d237'\n",
    "assert type(response_list) == list\n",
    "assert len(response_list) == 1333\n",
    "assert response_list[0] == ['S2701_C05_001E', 'state', 'county', 'tract']\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### *Exercise*\n",
    "\n",
    "2. (3 points) Convert the response to a pandas DataFrame. <br>\n",
    "2.1. Assign the first list of the nested list as the column names. <br>\n",
    "2.2. Assign the rest of the nested list as the data. <br>\n",
    "\n",
    "3. (3 points) Create a new column ('GEOID') by combining 'state', 'county', and 'tract' columns. <br>\n",
    "\n",
    "```python\n",
    "# Convert the response to a pandas DataFrame\n",
    "results_df = pd.DataFrame(data=`Slice of the rest of the nested list`, columns=`Slice of the first list of the nested list`)\n",
    "\n",
    "# Create a new column 'GEOID' by combining 'state', 'county', and 'tract' columns\n",
    "results_df['GEOID'] = `Combine 'state', 'county', and 'tract' columns of the 'results_df' DataFrame` \n",
    "results_df\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Convert the response to a pandas DataFrame\n",
    "results_df = pd.DataFrame(data=`Slice of the nested list`, columns=`Slice of the nested list`)\n",
    "\n",
    "# Create a new column 'GEOID' by combining 'state', 'county', and 'tract' columns\n",
    "results_df['GEOID'] = `Add Columns`\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Test code for the previous function. \n",
    "This cell should NOT give any errors when it is run.\"\"\"\n",
    "\n",
    "assert type(results_df) == pd.DataFrame\n",
    "assert results_df.shape[0] == 1332\n",
    "assert 'S2701_C05_001E' in results_df.columns\n",
    "assert 'GEOID' in results_df.columns\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### *Exercise*\n",
    "\n",
    "4. (3 points) Join `tract_geom` GeoDataFrame and `results_df` DataFrame based on `GEOID` column, and save the result as `tract_ins`. <br>\n",
    "\n",
    "\n",
    "``` python\n",
    "tract_ins = `DATAFRAME A`.merge(`DATAFRAME B`, on=`COLUMN NAME`)\n",
    "```\n",
    "\n",
    "5. (3 points) Rename `S2701_C05_001E` column as `No_HS_pct`. <br>\n",
    "\n",
    "``` python\n",
    "tract_ins = tract_ins.rename(columns={`OLD COLUMN NAME`: `NEW COLUMN NAME`})\n",
    "```\n",
    "\n",
    "6. (3 points) Change the data type of `No_HS_pct` column to float. <br>\n",
    "\n",
    "``` python\n",
    "`DATAFRAME`[`COLUMN NAME`] = `DATAFRAME`[`COLUMN NAME`].astype(`DATA TYPE`)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "# Join `tract_geom` GeoDataFrame and `results_df` DataFrame based on `GEOID` column\n",
    "tract_ins = `DATAFRAME A`.merge(`DATAFRAME B`, on=`COLUMN NAME`)\n",
    "\n",
    "# Rename `S2701_C05_001E` column as `No_HS_pct`\n",
    "tract_ins = tract_ins.rename(columns={`OLD COLUMN NAME`: `NEW COLUMN NAME`})\n",
    "\n",
    "# Change the data type of `No_HS_pct` column to float\n",
    "`DATAFRAME`[`COLUMN NAME`] = `DATAFRAME`[`COLUMN NAME`].astype(`DATA TYPE`)\n",
    "\n",
    "tract_ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Test code for the previous function. \n",
    "This cell should NOT give any errors when it is run.\"\"\"\n",
    "\n",
    "assert 'S2701_C05_001E' not in tract_ins.columns\n",
    "assert 'No_HS_pct' in tract_ins.columns\n",
    "assert tract_ins['No_HS_pct'].dtypes == float\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Calculate Correlation Coefficient between Poverty and No Health Insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Null value (-666666666.0) with 0 in the 'No_HS_pct' column\n",
    "tract_ins['No_HS_pct'].replace(-666666666.0, 0, inplace=True)\n",
    "\n",
    "# Merge the 'tract_ins' and 'tract_pov' DataFrames\n",
    "tract_gdf = tract_geom.merge(tract_ins[['GEOID', 'No_HS_pct']], on='GEOID')\n",
    "tract_gdf = tract_gdf.merge(tract_pov[['GEOID', 'Poverty_ratio']], on='GEOID')\n",
    "tract_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 10))\n",
    "\n",
    "# Plot the poverty ratio\n",
    "tract_gdf.plot('Poverty_ratio', ax=axes[0], legend=True, scheme='NaturalBreaks', cmap='Reds')\n",
    "\n",
    "# Plot the percentage of people without health insurance\n",
    "tract_gdf.plot('No_HS_pct', ax=axes[1], legend=True, scheme='NaturalBreaks', cmap='Reds')\n",
    "\n",
    "axes[0].set_title('Poverty Ratio')\n",
    "axes[1].set_title('No Health Insurance')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_axis_off()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef, pval = pearsonr(tract_gdf['Poverty_ratio'], tract_gdf['No_HS_pct'])\n",
    "\n",
    "print(f\"Pearson's correlation coefficient: {coef:.2f}\")\n",
    "print(f\"P-value: {pval:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "ax.scatter(tract_gdf['Poverty_ratio'], tract_gdf['No_HS_pct'], s=5, color='black', alpha=0.5)\n",
    "ax.set_xlabel('Poverty Ratio')\n",
    "ax.set_ylabel('No Health Insurance')\n",
    "\n",
    "x = tract_gdf['Poverty_ratio'].values\n",
    "y = tract_gdf['No_HS_pct'].values\n",
    "\n",
    "ax.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Caculate Spatial Correlation (Bivariate Moran's I and Bivariate Local Moran's I)\n",
    "\n",
    "Global **Bivariate Moran's I** demonstrates how geographical phenomena are correlated over space, meaning whether closer things is more related than distant things. The method provides an index with the range -1 to 1; namely, -1 is a strong negative spatial autocorrelation and 1 is a strong positive spatial autocorrelation.\n",
    "<br><br>\n",
    "While Global Bivariate Moran's I only provides one index to demonstrate spatial autocorrelation, **Bivariate Local Indicator of Spatial Association (LISA)**, as known as Bivariate Local Moran's I explains where high (i.e., HH Cluster) and low (LL Cluster) values are clustered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure will demonstrate what **contiguity** means. Here, we use Queen's case. \n",
    "\n",
    "<div>\n",
    "<img src=\"./image/contiguity.jpg\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate spatial relationship (contiguity) of geometry\n",
    "w = libpysal.weights.Queen.from_dataframe(tract_gdf) \n",
    "\n",
    "w.neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Syntax for Bivariate Moran's I and Bivariate Local Moran's I are as follows:\n",
    "\n",
    "```python\n",
    "# Bivariate Moran's I\n",
    "bv_mi = esda.moran.Moran_BV(`VARIABLE 1`, `VARIABLE 2`, `SPATIAL WEIGHTS MATRIX`)\n",
    "\n",
    "# Bivariate Local Moran's I\n",
    "bv_lm = esda.moran.Moran_Local_BV(`VARIABLE 1`, `VARIABLE 2`, `SPATIAL WEIGHTS MATRIX`)\n",
    "```\n",
    "\n",
    "bv_mi has the following attributes:\n",
    "* `I` : Bivariate Moran's I value\n",
    "* `p_sim` : p-value <br>\n",
    "\n",
    "source: https://pysal.org/esda/generated/esda.Moran_BV.html#esda.Moran_BV\n",
    "\n",
    "bv_lm has the following attributes:\n",
    "* `Is` : Bivariate Local Moran's I value\n",
    "* `q` : Quadrant (HH, HL, LH, LL)\n",
    "* `p_sim` : p-value\n",
    "\n",
    "source: https://pysal.org/esda/generated/esda.Moran_Local_BV.html#esda.Moran_Local_BV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAclulate Bivariate Moran's I\n",
    "bv_mi = esda.Moran_BV(tract_gdf['Poverty_ratio'], tract_gdf['No_HS_pct'], w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moran's I value\n",
    "bv_mi.I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moran's I p-value (significance level)\n",
    "bv_mi.p_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Local Bivariate Moran's I\n",
    "bv_lm = esda.Moran_Local_BV(tract_gdf['Poverty_ratio'], tract_gdf['No_HS_pct'], w, seed=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification of Bivariate Local Moran's I\n",
    "# 1: High-High, 2: Low-High, 3: Low-Low, 4: High-Low\n",
    "bv_lm.q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P-value of Bivariate Local Moran's I\n",
    "bv_lm.p_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot Bivariate Local Moran's I result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the results of Bivariate Local Moran's I to the GeoDataFrame\n",
    "tract_gdf['BV_LM'] = bv_lm.q\n",
    "tract_gdf['BV_LM_pval'] = bv_lm.p_sim\n",
    "tract_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter results of Bivariate LISA into each census region based on the p-value\n",
    "lm_dict = {1: 'HH', 2: 'LH', 3: 'LL', 4: 'HL'}\n",
    "for idx in range(tract_gdf.shape[0]):\n",
    "    if bv_lm.p_sim[idx] < 0.05:\n",
    "        tract_gdf.loc[idx, f'LISA_CLS'] = lm_dict[bv_lm.q[idx]]\n",
    "    else:\n",
    "        tract_gdf.loc[idx, f'LISA_CLS'] = 'NA'\n",
    "\n",
    "tract_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of each classification\n",
    "tract_gdf['LISA_CLS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "lisa_color = {'HH': '#FF0000', # Red\n",
    "              'LH': '#FFC0CB', # Pink\n",
    "              'LL': '#0000FF', # Blue\n",
    "              'HL': '#87CEEB', # Skyblue\n",
    "              'NA': '#f0f0f0'  # Light grey\n",
    "             } \n",
    "\n",
    "tract_gdf.loc[tract_gdf['LISA_CLS'] == 'NA'].plot(ax=ax, color=lisa_color['NA'])\n",
    "tract_gdf.loc[tract_gdf['LISA_CLS'] == 'HH'].plot(ax=ax, color=lisa_color['HH'])\n",
    "tract_gdf.loc[tract_gdf['LISA_CLS'] == 'LH'].plot(ax=ax, color=lisa_color['LH'])\n",
    "tract_gdf.loc[tract_gdf['LISA_CLS'] == 'LL'].plot(ax=ax, color=lisa_color['LL'])\n",
    "tract_gdf.loc[tract_gdf['LISA_CLS'] == 'HL'].plot(ax=ax, color=lisa_color['HL'])\n",
    "\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify the code using a for loop\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "for key,val in lisa_color.items():\n",
    "    tract_gdf.loc[tract_gdf['LISA_CLS'] == key].plot(ax=ax, color=val)\n",
    "\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Calculate Spatial Correlation for SVI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Social Vulnerability Index (SVI) data of Cook County, IL\n",
    "tract_svi = gpd.read_file('./data/SVI_Cook_IL.geojson')\n",
    "\n",
    "# Replace Null values (-999) with 0\n",
    "tract_svi = tract_svi.replace(-999, 0)\n",
    "\n",
    "tract_svi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(['RPL_THEME1', 'RPL_THEME2', 'RPL_THEME3', 'RPL_THEME4']):\n",
    "    tract_svi.plot(col, ax=axes[idx], scheme='NaturalBreaks', cmap='Reds')\n",
    "    axes[idx].set_title(col)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### *Exercise*\n",
    "\n",
    "7. (3 points) Calculate conventional correlation (Pearson's r) between `RPL_THEME1` and `RPL_THEME3` columns in `tract_svi` GeoDataFrame. <br>\n",
    "\n",
    "```python\n",
    "   r_coef, p_value = pearsonr(`DATAFRAME`[`COLUMN 1`], `DATAFRAME`[`COLUMN 2`])\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "r_coef, p_value = pearsonr(`DATAFRAME`[`COLUMN 1`], `DATAFRAME`[`COLUMN 2`])\n",
    "\n",
    "print(f\"Pearson's correlation coefficient: {r_coef:.2f}, P-value: {p_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Test code for the previous function. \n",
    "This cell should NOT give any errors when it is run.\"\"\"\n",
    "\n",
    "assert round(r_coef, 2) == 0.83\n",
    "assert p_value == 0.0\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### *Exercise*\n",
    "\n",
    "8. (3 points) Calculate contiguity between census tracts in `tract_svi` GeoDataFrame <br>\n",
    "\n",
    "```python\n",
    "   w_svi = libpysal.weights.Queen.from_dataframe(`GeoDataFrame`)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "w_svi = libpysal.weights.Queen.from_dataframe(`GeoDataFrame`)\n",
    "\n",
    "w_svi.neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Test code for the previous function. \n",
    "This cell should NOT give any errors when it is run.\"\"\"\n",
    "\n",
    "assert len(w_svi.neighbors) == 1331 \n",
    "assert w_svi.neighbors[0] == [1169, 659, 820, 662, 663, 716, 766]\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### *Exercise*\n",
    "\n",
    "9. (3 points) Calculate Bivariate Moran's I and Bivariate Local Moran's I by entering appropriate values in the following syntax. <br>You want to calculate the spatial correlation between `RPL_THEME1` and `RPL_THEME3`.  <br>\n",
    "\n",
    "\n",
    "```python\n",
    "   # Bivariate Moran's I\n",
    "   bv_mi_svi = esda.moran.Moran_BV(`VARIABLE 1`, `VARIABLE 2`, `SPATIAL WEIGHTS MATRIX`)\n",
    "\n",
    "   # Bivariate Local Moran's I\n",
    "   bv_lm_svi = esda.moran.Moran_Local_BV(`VARIABLE 1`, `VARIABLE 2`, `SPATIAL WEIGHTS MATRIX`, seed=17)\n",
    "```\n",
    "\n",
    "**Note**: seed is used to ensure the reproducibility of the result. Please keep the value as 17. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "# Bivariate Moran's I\n",
    "bv_mi_svi = esda.moran.Moran_BV(`VARIABLE 1`, `VARIABLE 2`, `SPATIAL WEIGHTS MATRIX`)\n",
    "\n",
    "# Bivariate Local Moran's I\n",
    "bv_lm_svi = esda.moran.Moran_Local_BV(`VARIABLE 1`, `VARIABLE 2`, `SPATIAL WEIGHTS MATRIX`, seed=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Test code for the previous function. \n",
    "This cell should NOT give any errors when it is run.\"\"\"\n",
    "\n",
    "assert round(bv_mi_svi.I, 3) == 0.688\n",
    "assert round(bv_mi_svi.p_sim, 3) == 0.001\n",
    "assert list(bv_lm_svi.q[0:5]) == [1, 1, 1, 1, 3]\n",
    "assert list(bv_lm_svi.p_sim[0:5]) == [0.001, 0.003, 0.164, 0.302, 0.011]\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### *Exercise*\n",
    "\n",
    "10. (3 points) Examine the following website to understand the meaning of the Bivariate Local Moran's I result. <br>\n",
    "Then, assign the appropriate results of quadrant and significant level (p-value) to `bv_lm_svi` and `bv_lm_svi_pval` in `tract_svi` GeoDataFrame, respectively. <br>\n",
    "\n",
    "website: https://pysal.org/esda/generated/esda.Moran_Local_BV.html#esda.Moran_Local_BV\n",
    "\n",
    "```python\n",
    "   tract_svi['bv_lm_svi'] = `Bivariate Local Morans I result`\n",
    "   tract_svi['bv_lm_svi_pval'] = `Bivariate Local Morans I p-value`\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "tract_svi['bv_lm_svi'] = `Bivariate Local Morans I result`\n",
    "tract_svi['bv_lm_svi_pval'] = `Bivariate Local Morans I p-value`\n",
    "\n",
    "tract_svi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Test code for the previous function. \n",
    "This cell should NOT give any errors when it is run.\"\"\"\n",
    "\n",
    "assert 'bv_lm_svi' in tract_svi.columns\n",
    "assert 'bv_lm_svi_pval' in tract_svi.columns\n",
    "assert tract_svi.at[10, 'bv_lm_svi'] == 4\n",
    "assert tract_svi.at[10, 'bv_lm_svi_pval'] == 0.103\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon the completion of the exercise 10, the following code will give you the same map as shown below. \n",
    "\n",
    "<div>\n",
    "<img src=\"./image/svi_bv_local_moran.png\" width=\"300\"/>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter results of Bivariate LISA into each census region\n",
    "lm_dict = {1: 'HH', 2: 'LH', 3: 'LL', 4: 'HL'}\n",
    "\n",
    "for idx, row in tract_svi.iterrows():\n",
    "    if row['bv_lm_svi_pval'] < 0.05:\n",
    "        tract_svi.loc[idx, f'LISA_CLS'] = lm_dict[row['bv_lm_svi']]\n",
    "    else:\n",
    "        tract_svi.loc[idx, f'LISA_CLS'] = 'NA'\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "for key,val in lisa_color.items():\n",
    "    tract_svi.loc[tract_svi['LISA_CLS'] == key].plot(ax=ax, color=val)\n",
    "\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. K-Means Clustering\n",
    "\n",
    "K-means clustering is a type of unsupervised learning, which is used when you have unlabeled data. This appraoch can find out the characteristics of regions such as a group of regions has high value for certain SVI data while having low value for other SVI data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def determine_number_of_cluster(array):\n",
    "    km_cost = []  # Sum of squared distances of samples to their closest cluster center.\n",
    "    distortions = []  # the average of the squared distances from the cluster centers of the respective clusters.Typically, the Euclidean distance metric is used.\n",
    "    km_silhouette = {}\n",
    "\n",
    "    for i in range(2, 11):\n",
    "        KM = KMeans(n_clusters=i, max_iter=999, n_init = 99, random_state=17)\n",
    "        KM.fit(array)\n",
    "\n",
    "        # Calculate Silhouette Scores\n",
    "        preds = KM.predict(array)\n",
    "        silhouette = silhouette_score(array, preds)\n",
    "        km_silhouette[i] = silhouette\n",
    "\n",
    "    print(max(km_silhouette, key=km_silhouette.get))\n",
    "        \n",
    "    return km_silhouette\n",
    "\n",
    "\n",
    "def kmeans_cluster(array, num_of_cluster):\n",
    "    kmeans = KMeans(n_clusters=num_of_cluster, max_iter=999, n_init = 99, random_state=17)\n",
    "    kmeans.fit(array)\n",
    "    y_kmeans = kmeans.predict(array)\n",
    "    \n",
    "    cluster_df = pd.DataFrame({'cluster': y_kmeans}, index=array.index)\n",
    "    cluster_df['cluster'] = cluster_df['cluster'].astype(str)\n",
    "    \n",
    "    return cluster_df\n",
    "\n",
    "silhouette_scores = determine_number_of_cluster(tract_svi[['RPL_THEME1', 'RPL_THEME2', 'RPL_THEME3', 'RPL_THEME4']])\n",
    "print({idx: round(val, 4) for idx, val in silhouette_scores.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select the second highest silhouette coefficient as the highest silhouette coefficient indicates only 2 groups. \n",
    "mi_copy = kmeans_cluster(tract_svi[['RPL_THEME1', 'RPL_THEME2', 'RPL_THEME3', 'RPL_THEME4']], 3)\n",
    "tract_svi['cluster'] = mi_copy['cluster']\n",
    "tract_svi['cluster'] = tract_svi['cluster'].astype(str)\n",
    "tract_svi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_kw = dict(width_ratios=[1, 1], height_ratios=[1, 1, 1])\n",
    "fig, axd = plt.subplot_mosaic([['left', 'rightc0'], \n",
    "                               ['left', 'rightc1'], \n",
    "                               ['left', 'rightc2'],\n",
    "                              ],\n",
    "                              gridspec_kw=gs_kw, \n",
    "                              figsize=(15, 8),\n",
    "                            #   constrained_layout=True\n",
    "                             )\n",
    "print(type(axd), axd)\n",
    "\n",
    "tract_svi.plot('cluster', ax=axd['left'], legend=True, cmap='Set1')\n",
    "\n",
    "for cls in [0, 1, 2]:\n",
    "    temp_df = tract_svi.loc[tract_svi['cluster'] == str(cls), ['RPL_THEME1', 'RPL_THEME2', 'RPL_THEME3', 'RPL_THEME4']]\n",
    "    axd[f'rightc{cls}'].boxplot(temp_df, showfliers=False)\n",
    "    axd[f'rightc{cls}'].set_title(f'Cluster {cls}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
